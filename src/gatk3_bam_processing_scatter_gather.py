#!/usr/bin/env python
# coding: utf-8
# gatk3_bam_processing_scatter_gather 0.0.1
# Generated by dx-app-wizard.
#
# Scatter-process-gather execution pattern: Your app will split its
# input into multiple pieces, each of which will be processed in
# parallel, after which they are gathered together in some final
# output.
#
# This pattern is very similar to the "parallelized" template.  What
# it does differently is that it formally breaks out the "scatter"
# phase as a separate black-box entry point in the app.  (As a side
# effect, this requires a "map" entry point to call "process" on each
# of the results from the "scatter" phase.)
#
# Note that you can also replace any entry point in this execution
# pattern with an API call to run a separate app or applet.
#
# The following is a Unicode art picture of the flow of execution.
# Each box is an entry point, and vertical lines indicate that the
# entry point connected at the top of the line calls the entry point
# connected at the bottom of the line.  The letters represent the
# different stages in which the input is transformed, e.g. the output
# of the "scatter" entry point ("array:B") is given to the "map" entry
# point as input.  The "map" entry point calls as many "process" entry
# points as there are elements in its array input and gathers the
# results in its array output.
#
#          ┌──────┐
#       A->│ main │->D (output from "postprocess")
#          └┬─┬─┬─┘
#           │ │ │
#          ┌┴──────┐
#       A->│scatter│->array:B
#          └───────┘
#             │ │
#            ┌┴──────────────┐
#   array:B->│      map      │->array:C
#            └─────────┬─┬─┬─┘
#               │      │ . .
#               │     ┌┴──────┐
#               │  B->│process│->C
#               │     └───────┘
#            ┌──┴────────┐
#   array:C->│postprocess│->D
#            └───────────┘
#
# A = original app input, split up by "scatter" into pieces of type B
# B = an input that will be provided to a "process" entry point
# C = the output of a "process" entry point
# D = app output aggregated from the outputs of the "process" entry points
#
# See https://wiki.dnanexus.com/Developer-Portal for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import os
import dxpy
import logging
import time


logger = logging.getLogger(__name__)
logger.addHandler(dxpy.DXLogHandler())
logger.propagate = False


try:
    from dx_applet_utilities import (
        common_job_operations as dx_utils,
        manage_command_execution as dx_exec,
        prepare_job_resources as dx_resources,
        prepare_scatter_gather_jobs as dx_scatter)
except ImportError:
    logger.error("Make sure to add the dx_applet_utilities to execDepends in dxapp.json!")
    sys.exit(1)


@dxpy.entry_point("gatk_realignment")
def process(scattered_input, additional_input):
    # Fill in code here to process the input and create output.

    # As always, you can choose not to return output if the
    # "postprocess" stage does not require any input, e.g. rows have
    # been added to a GTable that has been created in advance.  Just
    # make sure that the "postprocess" job does not run until all
    # "process" jobs have finished by making it wait for "map" to
    # finish using the depends_on argument (this is already done for
    # you in the invocation of the "postprocess" job in "main").

    return { "process_output": "process placeholder output" }


@dxpy.entry_point("gatk_base_recalibrator")
def process(scattered_input, additional_input):
    # Fill in code here to process the input and create output.

    # As always, you can choose not to return output if the
    # "postprocess" stage does not require any input, e.g. rows have
    # been added to a GTable that has been created in advance.  Just
    # make sure that the "postprocess" job does not run until all
    # "process" jobs have finished by making it wait for "map" to
    # finish using the depends_on argument (this is already done for
    # you in the invocation of the "postprocess" job in "main").

    return { "process_output": "process placeholder output" }


@dxpy.entry_point("gatk_apply_bqsr")
def postprocess(process_outputs, additional_input):
    # This is the "gather" phase which aggregates and performs any
    # additional computation after the "map" (and therefore after all
    # the "process") jobs are done.

    for item in process_outputs:
        print item

    return { "final_output": "postprocess placeholder output" }


@dxpy.entry_point("gather")
def map_entry_point(array_of_scattered_input, process_input):
    # The following calls "process" for each of the items in
    # *array_of_scattered_input*, using as input the item in the
    # array, as well as the rest of the fields in *process_input*.
    process_jobs = []
    for item in array_of_scattered_input:
        process_input["scattered_input"] = item
        process_jobs.append(dxpy.new_dxjob(fn_input=process_input, fn_name="process"))
    return { "process_outputs": [subjob.get_output_ref("process_output") for subjob in process_jobs] }


@dxpy.entry_point("main")
def main(bam_files, sampleId, padding, reference, loglevel, number_of_nodes,
    downsample, downsample_fraction, regions_file=None, indel_vcf=None,
    dbsnp=None, advanced_rtc_options=None, advanced_ir_options=None,
    advanced_br_options=None, advanced_pr_options=None):

    """This is a dx applet that runs on the DNAnexus platform. This will run
    GATK3 best practices pipeline using scatter gather. This is very useful for
    processing WGS datasets. This function is the controller of the pipeline,
    which will scatter data, process it and then gather it for final processing.

    :param: `bam_files`:
    :param: `sampleId`:
    :param: `padding`:
    :param: `reference`:
    :param: `loglevel`:
    :param: `number_of_nodes`
    :param: `downsample`:
    :param: `downsample_fraction`:
    :param: `regions_file`:
    :param: `indel_vcf`:
    :param: `dbsnp`:
    :param: `advanced_rtc_options`:
    :param: `advanced_ir_options`:
    :param: `advanced_br_options`:
    :param: `advanced_pr_options`:
    """

    logger.setLevel(loglevel)
    logger.info("GATK3 scatter gather controller. Number of nodes for scatter jobs: {0}".format(number_of_nodes))

    # Balance jobs based on the file sizes of file from input

    file_sizes = {}
    file_objects = {}
    for bam_file in bam_files:
        file_size = int(dxpy.DXFile(bam_file).describe()["size"])
        file_name = dxpy.DXFile(bam_file).describe()["name"]
        file_sizes[file_name] = file_size
        file_objects[file_name] = bam_file

    balanced_jobs_object = dx_scatter.distribute_files_by_size(
        file_sizes=file_sizes,
        dx_file_objects=file_objects,
        number_of_nodes=number_of_nodes)

    # GATK in/del realignment phase

    gatk_rtc_ir_jobs = []
    for job_name, file_objects in balanced_jobs_object.items():

        # create GATK3 Realignment node
        logger.info("Create GATK3 Realignment Job")
        gatk_rtc_ir_jobs.append(
            dxpy.new_dxjob(
                fn_input={
                    "bam_files": file_objects,
                    "reference": reference,
                    "regions_file": regions_file,
                    "padding": padding,
                    "indel_vcf": indel_vcf,
                    "sampleId": sampleId,
                    "advanced_rtc_options": advanced_rtc_options,
                    "advanced_ir_options": advanced_ir_options,
                    "downsample": downsample,
                    "downsample_fraction": downsample_fraction,
                    "loglevel": loglevel
                },
                fn_name="gatk_realignment"
            )
        )

    return output

dxpy.run()
